# -*- coding: utf-8 -*-
"""SML_A4_Ans1,4.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/10OBqdg6MgR6S9K5MeBHez4ghpzo6k-ph
"""



"""Ans1)"""

from google.colab import drive
drive.mount('/content/drive')

import gzip
import pickle
import os
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
def plot_confusion_matrix(cm, classes=None, title='Confusion matrix'):
    """Plots a confusion matrix."""
    if classes is not None:
        sns.heatmap(cm, cmap="YlGnBu", xticklabels=classes, yticklabels=classes, vmin=0., vmax=1., annot=True, annot_kws={'size':10})
    else:
        sns.heatmap(cm, vmin=0., vmax=1.)
    plt.title(title)
    plt.ylabel('True label')
    plt.xlabel('Predicted label')
def images_file_read(file_name):
    with gzip.open(file_name, 'r') as f:
        # first 4 bytes is a magic number
        magic_number = int.from_bytes(f.read(4), 'big')
        # second 4 bytes is the number of images
        image_count = int.from_bytes(f.read(4), 'big')
        # third 4 bytes is the row count
        row_count = int.from_bytes(f.read(4), 'big')
        # fourth 4 bytes is the column count
        column_count = int.from_bytes(f.read(4), 'big')
        # rest is the image pixel data, each pixel is stored as an unsigned byte
        # pixel values are 0 to 255
        image_data = f.read()
        images = np.frombuffer(image_data, dtype=np.uint8)\
            .reshape((image_count, row_count, column_count))
        return images
def labels_file_read(file_name):
    with gzip.open(file_name, 'r') as f:
        # first 4 bytes is a magic number
        magic_number = int.from_bytes(f.read(4), 'big')
        # second 4 bytes is the number of labels
        label_count = int.from_bytes(f.read(4), 'big')
        # rest is the label data, each label is stored as unsigned byte
        # label values are 0 to 9
        label_data = f.read()
        labels = np.frombuffer(label_data, dtype=np.uint8)
        return labels
train_x = images_file_read("/content/drive/MyDrive/mnist.zip (Unzipped Files)/mnist/train-images-idx3-ubyte.gz")
print(train_x.shape)
train_y = labels_file_read("/content/drive/MyDrive/mnist.zip (Unzipped Files)/mnist/train-labels-idx1-ubyte.gz")
test_x = images_file_read("/content/drive/MyDrive/mnist.zip (Unzipped Files)/mnist/t10k-images-idx3-ubyte.gz")
print(test_x.shape)
test_y = labels_file_read("/content/drive/MyDrive/mnist.zip (Unzipped Files)/mnist/t10k-labels-idx1-ubyte.gz")
plt.imshow(train_x[1])
print("Label :" ,  train_y[1])

from sklearn.tree import DecisionTreeRegressor
r1 = DecisionTreeRegressor(max_depth=1)

train_x=train_x.reshape(60000,784)

test_x=test_x.reshape(10000,784)

start=r1.fit(train_x,train_y)
train_out1 = r1.predict(train_x)
p1 = r1.predict(test_x)
count=0
l = len(test_x)
for i in range(len(test_x)):
  if(round(p1[i])==test_y[i]):
    count+=1
print("Accuracy without any booster: ", count/l*100, "%")

h1=DecisionTreeRegressor(max_depth=1)

temp = np.zeros(60000).reshape(60000,)
for i in range(len(train_y)):
  temp[i] = train_y[i] - train_out1[i]

print(temp)

it1=h1.fit(train_x,temp)
train_out2 = h1.predict(train_x)
p2 = h1.predict(test_x)
p3 = p1+(0.1)*p2
count=0
l = len(test_x)
for i in range(len(test_x)):
  if(round(p3[i])==test_y[i]):
    count+=1
print("Accuracy of iteration 1: ", count/l*100,"%")

h2=DecisionTreeRegressor(max_depth=1)

temp1 = np.zeros(60000).reshape(60000,)
for i in range(len(train_y)):
  temp1[i] = train_y[i] - train_out1[i] - train_out2[i]

it2=h2.fit(train_x,temp1)
train_out3 = h2.predict(train_x)
p4 = h2.predict(test_x)
p5 = p3+(0.1)*p4
count=0
l = len(test_x)
for i in range(len(test_x)):
  if(round(p5[i])==test_y[i]):
    count+=1
print("Accuracy of iteration 2: ", count/l*100,"%")

h3=DecisionTreeRegressor(max_depth=1)

temp2 = np.zeros(60000).reshape(60000,)
for i in range(len(train_y)):
  temp2[i] = temp1[i] - train_out3[i]

it3=h3.fit(train_x,temp2)
train_out4 = h3.predict(train_x)
p6 = h3.predict(test_x)
p7 = p5+(0.1)*p6
count=0
l = len(test_x)
for i in range(len(test_x)):
  if(round(p7[i])==test_y[i]):
    count+=1
print("Accuracy of iteration 3: ", count/l*100,"%")

h4=DecisionTreeRegressor(max_depth=1)

temp3 = np.zeros(60000).reshape(60000,)
for i in range(len(train_y)):
  temp3[i] = temp2[i] - train_out4[i]

it4=h4.fit(train_x,temp3)
train_out5 = h4.predict(train_x)
p8 = h4.predict(test_x)
p9 = p8+(0.1)*p7
count=0
l = len(test_x)
for i in range(len(test_x)):
  if(round(p9[i])==test_y[i]):
    count+=1
print("Accuracy of iteration 4:", count/l*100,"%")

h5=DecisionTreeRegressor(max_depth=1)

temp4 = np.zeros(60000).reshape(60000,)
for i in range(len(train_y)):
  temp4[i] = temp3[i] - train_out5[i]

it5=h5.fit(train_x,temp4)

p10 = h5.predict(test_x)
p11 = p10+(0.1)*p9
count=0
l = len(test_x)
for i in range(len(test_x)):
  if(round(p11[i])==test_y[i]):
    count+=1
print("Accuracy of iteration 5: ", count/l*100,"%")

"""Here, final accuracy is 9.8%. 
We have also assumed here that at each step the regressor used is a Decision Tree Regressor with max depth of 1.
If we take learning rate as 1, we get a max accuracy of 17% after 5 iterations.

Ans4)
"""

import gzip
import pickle
import os
import numpy as np
import matplotlib.pyplot as plt
def images_file_read(file_name):
    with gzip.open(file_name, 'r') as f:
        # first 4 bytes is a magic number
        magic_number = int.from_bytes(f.read(4), 'big')
        # second 4 bytes is the number of images
        image_count = int.from_bytes(f.read(4), 'big')
        # third 4 bytes is the row count
        row_count = int.from_bytes(f.read(4), 'big')
        # fourth 4 bytes is the column count
        column_count = int.from_bytes(f.read(4), 'big')
        # rest is the image pixel data, each pixel is stored as an unsigned byte
        # pixel values are 0 to 255
        image_data = f.read()
        images = np.frombuffer(image_data, dtype=np.uint8)\
            .reshape((image_count, row_count, column_count))
        return images
def labels_file_read(file_name):
    with gzip.open(file_name, 'r') as f:
        # first 4 bytes is a magic number
        magic_number = int.from_bytes(f.read(4), 'big')
        # second 4 bytes is the number of labels
        label_count = int.from_bytes(f.read(4), 'big')
        # rest is the label data, each label is stored as unsigned byte
        # label values are 0 to 9
        label_data = f.read()
        labels = np.frombuffer(label_data, dtype=np.uint8)
        return labels
train_x = images_file_read("/content/drive/MyDrive/mnist.zip (Unzipped Files)/mnist/train-images-idx3-ubyte.gz")
print(train_x.shape)
train_y = labels_file_read("/content/drive/MyDrive/mnist.zip (Unzipped Files)/mnist/train-labels-idx1-ubyte.gz")
test_x = images_file_read("/content/drive/MyDrive/mnist.zip (Unzipped Files)/mnist/t10k-images-idx3-ubyte.gz")
print(test_x.shape)
test_y = labels_file_read("/content/drive/MyDrive/mnist.zip (Unzipped Files)/mnist/t10k-labels-idx1-ubyte.gz")
plt.imshow(train_x[1])
print("Label :" ,  train_y[1])

import random
import time
random.seed(time.clock())
def generateRandom():
  temp=np.zeros(60000)
  for i in range(60000):
    temp[i] = random.randint(0,59999)
  return temp

print(generateRandom()[10])

train_x = train_x.reshape(60000,784)
test_x = test_x.reshape(10000,784)

from sklearn.tree import DecisionTreeClassifier
clf1 = DecisionTreeClassifier()
clf2 = DecisionTreeClassifier()  
clf3 = DecisionTreeClassifier()    
t1_x = np.zeros(60000*784).reshape(60000,784) 
t2_x = np.zeros(60000*784).reshape(60000,784)
t3_x = np.zeros(60000*784).reshape(60000,784)
t1_y = np.zeros(60000).reshape(60000,) 
t2_y = np.zeros(60000).reshape(60000,)
t3_y = np.zeros(60000).reshape(60000,)
bag1 = generateRandom()
for i in range(60000):
  index=int(bag1[i])
  # print(index)
  t1_x[i]=train_x[index]
  t1_y[i]=train_y[index]
bag2 = generateRandom()
for i in range(60000):
  index=int(bag2[i])
  t2_x[i]=train_x[index]
  t2_y[i]=train_y[index]
bag3 = generateRandom()
for i in range(60000):
  index=int(bag3[i])
  t3_x[i]=train_x[index]
  t3_y[i]=train_y[index]

clf1.fit(t1_x,t1_y)
clf2.fit(t2_x,t2_y)
clf3.fit(t3_x,t3_y)

p1=clf1.predict(test_x)
p2=clf2.predict(test_x)
p3=clf3.predict(test_x)

l=[0,0,0]
p=np.zeros(len(p1))
for i in range(len(p1)):
  # p[i] = p1[i]
  # if(p[i]!=p2[i] and p[i]==p3[i]):
  #   p[i]=p1[i]
  # elif(p2[i]==p3[i]):
  #   p[i]=p2[i]
  l[0]=p1[i]
  l[1]=p2[i]
  l[2]=p3[i]
  p[i] = max(l,key=l.count)

class_name = {0,1,2,3,4,5,6,7,8,9}
from sklearn.metrics import r2_score, explained_variance_score, confusion_matrix, accuracy_score, classification_report
cm3 = confusion_matrix(test_y, p)
cm_norm3 = cm3 / cm3.sum(axis=1).reshape(-1,1)

plot_confusion_matrix(cm_norm3, classes = class_name, title='Confusion matrix')
count=0
for i in range(len(p)):
  if(p[i]==test_y[i]):
    count+=1
print("Accuracy: ", count/len(p)*100, "%")



