# -*- coding: utf-8 -*-
"""SML_A4_Ans2,3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1rAdcoputy8ROXPcO4dv5VCqTQRJofRmo

Ans2)
"""

from google.colab import drive
drive.mount('/content/drive')

!pip install tensorflow

import numpy as np
import gzip
import sys
import pickle as cPickle
from keras.datasets import mnist
from keras.layers import Dropout
from matplotlib import pyplot as plt
import tensorflow as tf
from keras.models import Sequential
from keras.layers import Dense, Activation
from tensorflow.keras.utils import to_categorical
from keras import initializers
from keras import optimizers
# from matplotlib import pyplot
# from keras.callbacks import ModelCheckpoint
# from keras.models import load_model
# from keras.preprocessing.image import ImageDataGenerator
# from keras.datasets import cifar10
# from keras.layers.normalization import BatchNormalization
# from array import array
import seaborn as sns
def plot_confusion_matrix(cm, classes=None, title='Confusion matrix'):
    """Plots a confusion matrix."""
    if classes is not None:
        sns.heatmap(cm, cmap="YlGnBu", xticklabels=classes, yticklabels=classes, vmin=0., vmax=1., annot=True, annot_kws={'size':10})
    else:
        sns.heatmap(cm, vmin=0., vmax=1.)
    plt.title(title)
    plt.ylabel('True label')
    plt.xlabel('Predicted label')

import pandas as pd
df_train = pd.read_csv("/content/drive/MyDrive/fminst.zip (Unzipped Files)/fashion-mnist_train.csv")
df_test = pd.read_csv("/content/drive/MyDrive/fminst.zip (Unzipped Files)/fashion-mnist_test.csv")
label = {0:"T-shirt/top",
1 :"Trouser",
2 :"Pullover",
3 :"Dress",
4 :"Coat",
5 :"Sandal",
6 :"Shirt",
7 :"Sneaker",
8 :"Bag",
9 :"Ankle boot"}

train_x = np.array(df_train.iloc[:,1:]).reshape(df_train.shape[0],28,28)
train_y = np.array(df_train.iloc[:,0])
test_x = np.array(df_test.iloc[:,1:]).reshape(df_test.shape[0],28,28)
test_y = np.array(df_test.iloc[:,0])

train_y.shape

train_x.shape

print('Shape of images is..',train_x.shape)
print('Shape of labels is..',train_y.shape)
print('Showing orig image')
pixels = train_x[1,:,:]
plt.imshow(pixels, cmap='gray')
plt.show()
print('pixels..',pixels[10:15,10:15])

#get val and test set
val_images = test_x[0:500,:,:]
val_labels = test_y[0:500]
# test_images = test_i[500:,:,:]
# test_labels = test_labelsall[500:]

train_x = (train_x / 255) - 0.5
test_x = (test_x / 255) - 0.5
val_images = (val_images / 255) - 0.5

train_x = train_x.reshape((-1, 784))
test_x = test_x.reshape((-1, 784))
val_images = val_images.reshape((-1, 784))

model = Sequential()
model.add(Dense(128, input_dim=784, trainable=True,activation='relu', use_bias=True, 
                kernel_initializer=initializers.he_normal(seed=None)))

model.add(Dense(64, input_dim=128,activation='relu', use_bias=False, 
                kernel_initializer=initializers.he_normal(seed=None)))
model.add(Dense(64, input_dim=64,activation='relu', use_bias=False, 
                kernel_initializer=initializers.he_normal(seed=None)))
model.add(Dense(10, trainable=True, activation='softmax'))
sgd = tf.keras.optimizers.SGD(lr=0.01)
model.compile(
  optimizer=sgd,
  loss='categorical_crossentropy',
  metrics=['accuracy'],
)
model.summary()

train_y = to_categorical(train_y)
test_y = to_categorical(test_y)

history = model.fit(train_x,train_y, validation_data=(test_x, test_y), epochs=30, verbose=0)

from matplotlib import pyplot
train_acc = model.evaluate(train_x, train_y, verbose=0)
test_acc = model.evaluate(test_x, test_y, verbose=0)
# pyplot.subplot(211)
# pyplot.title('Loss')
# pyplot.plot(history.history['loss'], label='train')
# pyplot.plot(history.history['val_loss'], label='test')
# pyplot.legend()
# # plot accuracy during training
# pyplot.subplot(212)
# pyplot.title('Accuracy')
# pyplot.plot(history.history['accuracy'], label='train')
# pyplot.plot(history.history['val_accuracy'], label='test')
# pyplot.legend()
# pyplot.show()
print("Test Accuracy is : ", test_acc[1])

plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

l=[0]*10
m=[0]*10
y_pred=model.predict(test_x)
pred=np.zeros(len(y_pred))
t_y=np.zeros(len(y_pred))

for i in range(len(y_pred)):
  for j in range(10):
    l[j]=y_pred[i][j]
    m[j]=test_y[i][j]
  pred[i]=l.index(max(l))
  t_y[i] = m.index(max(m))  
    
print(pred,t_y)

print(test_y)

class_name=[0,1,2,3,4,5,6,7,8,9]
from sklearn.metrics import r2_score, explained_variance_score, confusion_matrix, accuracy_score, classification_report
cm3 = confusion_matrix(t_y,pred )
cm_norm3 = cm3 / cm3.sum(axis=1).reshape(-1,1)

plot_confusion_matrix(cm_norm3, classes = class_name, title='Confusion matrix')

"""Hyperparameters used here are: 
1)Learning rate = 0.01
2)Epochs = 100

----------------------------------------------------------------------------------------

Ans3)
"""

import gzip
import pickle
import os
import numpy as np
import matplotlib.pyplot as plt
def images_file_read(file_name):
    with gzip.open(file_name, 'r') as f:
        # first 4 bytes is a magic number
        magic_number = int.from_bytes(f.read(4), 'big')
        # second 4 bytes is the number of images
        image_count = int.from_bytes(f.read(4), 'big')
        # third 4 bytes is the row count
        row_count = int.from_bytes(f.read(4), 'big')
        # fourth 4 bytes is the column count
        column_count = int.from_bytes(f.read(4), 'big')
        # rest is the image pixel data, each pixel is stored as an unsigned byte
        # pixel values are 0 to 255
        image_data = f.read()
        images = np.frombuffer(image_data, dtype=np.uint8)\
            .reshape((image_count, row_count, column_count))
        return images
def labels_file_read(file_name):
    with gzip.open(file_name, 'r') as f:
        # first 4 bytes is a magic number
        magic_number = int.from_bytes(f.read(4), 'big')
        # second 4 bytes is the number of labels
        label_count = int.from_bytes(f.read(4), 'big')
        # rest is the label data, each label is stored as unsigned byte
        # label values are 0 to 9
        label_data = f.read()
        labels = np.frombuffer(label_data, dtype=np.uint8)
        return labels
train_x = images_file_read("/content/drive/MyDrive/mnist.zip (Unzipped Files)/mnist/train-images-idx3-ubyte.gz")
print(train_x.shape)
train_y = labels_file_read("/content/drive/MyDrive/mnist.zip (Unzipped Files)/mnist/train-labels-idx1-ubyte.gz")
test_x = images_file_read("/content/drive/MyDrive/mnist.zip (Unzipped Files)/mnist/t10k-images-idx3-ubyte.gz")
print(test_x.shape)
test_y = labels_file_read("/content/drive/MyDrive/mnist.zip (Unzipped Files)/mnist/t10k-labels-idx1-ubyte.gz")
plt.imshow(train_x[1])
print("Label :" ,  train_y[1])

print('Shape of images is..',train_x.shape)
print('Shape of labels is..',train_y.shape)
print('Showing orig image')
pixels = train_x[1,:,:]
plt.imshow(pixels, cmap='gray')
plt.show()
print('pixels..',pixels[10:15,10:15])

#get val and test set
val_images = test_x[0:500,:,:]
val_labels = test_y[0:500]
# test_images = test_i[500:,:,:]
# test_labels = test_labelsall[500:]

train_x = (train_x / 255) - 0.5
test_x = (test_x / 255) - 0.5
val_images = (val_images / 255) - 0.5

train_x = train_x.reshape((-1, 784))
test_x = test_x.reshape((-1, 784))
val_images = val_images.reshape((-1, 784))

model = Sequential()
model.add(Dense(512, input_dim=784, trainable=True,activation='relu', use_bias=True, 
                kernel_initializer=initializers.he_normal(seed=None)))

model.add(Dense(128, input_dim=512,activation='relu', use_bias=False, 
                kernel_initializer=initializers.he_normal(seed=None)))
model.add(Dense(64, input_dim=128,activation='relu', use_bias=False, 
                kernel_initializer=initializers.he_normal(seed=None)))
model.add(Dense(128, input_dim=64,activation='relu', use_bias=False, 
                kernel_initializer=initializers.he_normal(seed=None)))
model.add(Dense(512, input_dim=128,activation='relu', use_bias=False, 
                kernel_initializer=initializers.he_normal(seed=None)))
model.add(Dense(784, input_dim=512,activation='relu', use_bias=False, 
                kernel_initializer=initializers.he_normal(seed=None)))

# model.add(Dense(10, trainable=True, activation='softmax'))
sgd = tf.keras.optimizers.SGD(lr=0.01, momentum=0.9)
adam = tf.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-8)
model.compile(
  optimizer=adam,
  loss='mse'
)
model.summary()

# train_y = to_categorical(train_y)
# test_y = to_categorical(test_y)

history = model.fit(train_x,train_x, validation_data=(test_x, test_x), epochs=30, verbose=0)

plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

"""MNIST CLASSIFIER:"""

mnistClass = Sequential()
mnistClass.add(Dense(512, input_dim=784, trainable=True,activation='relu', use_bias=True, 
                kernel_initializer=initializers.he_normal(seed=None)))

mnistClass.add(Dense(128, input_dim=512,activation='relu', use_bias=False, 
                kernel_initializer=initializers.he_normal(seed=None)))
mnistClass.add(Dense(64, input_dim=128,activation='relu', use_bias=False, 
                kernel_initializer=initializers.he_normal(seed=None)))
mnistClass.add(Dense(32, input_dim=64,activation='relu', use_bias=False, 
                kernel_initializer=initializers.he_normal(seed=None)))
mnistClass.add(Dense(10, trainable=True, activation='softmax'))
sgd = tf.keras.optimizers.SGD(lr=0.01, momentum=0.9)
adam = tf.optimizers.Adam(lr=0.1, beta_1=0.9, beta_2=0.999, epsilon=1e-8)
mnistClass.compile(
  optimizer=sgd,
  loss='categorical_crossentropy',
  metrics=['accuracy'],
)
mnistClass.summary()

train_y = to_categorical(train_y)
test_y = to_categorical(test_y)

history = mnistClass.fit(train_x,train_y, validation_data=(test_x, test_y), epochs=10, verbose=0)

from matplotlib import pyplot
train_acc = mnistClass.evaluate(train_x, train_y, verbose=0)
test_acc = mnistClass.evaluate(test_x, test_y, verbose=0)
# print(train_acc, test_acc)
# print("TEST ACC: ", test_acc)
# # plot loss during training
# pyplot.subplot(211)
# pyplot.title('Loss')
# pyplot.plot(history.history['loss'], label='train')
# pyplot.plot(history.history['val_loss'], label='test')
# pyplot.legend()
# # plot accuracy during training
# pyplot.subplot(212)
# pyplot.title('Accuracy')
# pyplot.plot(history.history['accuracy'], label='train')
# pyplot.plot(history.history['val_accuracy'], label='test')
# pyplot.legend()
# pyplot.show()
print("Testing Accuracy: ",test_acc[1])

plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('mnistClass loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

l=[0]*10
m=[0]*10
y_pred=mnistClass.predict(test_x)
pred=np.zeros(len(y_pred))
t_y=np.zeros(len(y_pred))

for i in range(len(y_pred)):
  for j in range(10):
    l[j]=y_pred[i][j]
    m[j]=test_y[i][j]
  pred[i]=l.index(max(l))
  t_y[i] = m.index(max(m))  
    
print(pred,t_y)

class_name = {0,1,2,3,4,5,6,7,8,9}
from sklearn.metrics import r2_score, explained_variance_score, confusion_matrix, accuracy_score, classification_report
cm3 = confusion_matrix(t_y, pred)
cm_norm3 = cm3 / cm3.sum(axis=1).reshape(-1,1)

plot_confusion_matrix(cm_norm3, classes = class_name, title='Confusion matrix')

"""Learning rate=0.1 for Adam, 0.01 for SDG"""

